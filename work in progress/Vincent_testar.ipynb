{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HÄR FINNS MASSA KUL EXPERIMENT! Först här är en snygg visualisering words_per_occupation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load your dataset into a Pandas DataFrame\n",
    "df = pd.read_csv('clean_occup.csv')\n",
    "\n",
    "# create a dictionary to hold the descriptions for each occupation\n",
    "occupation_descriptions = {}\n",
    "\n",
    "# iterate over each occupation in the dataset\n",
    "for occupation in df['occupation'].unique():\n",
    "    # get all the descriptions for this occupation\n",
    "    occupation_df = df[df['occupation'] == occupation]\n",
    "    descriptions = [desc[14:] for desc in occupation_df['description'].tolist()]\n",
    "    # add the descriptions to the dictionary\n",
    "    occupation_descriptions[occupation] = descriptions\n",
    "\n",
    "# get the top 20 occupations with the most descriptions\n",
    "top_occupations = df['occupation'].value_counts().nlargest(20)\n",
    "\n",
    "# iterate over each of the top 20 occupations\n",
    "for occupation in top_occupations.index:\n",
    "    # concatenate all the descriptions for this occupation into a single string\n",
    "    text = ' '.join(occupation_descriptions[occupation])\n",
    "    # create a dictionary of word frequencies for this occupation\n",
    "    word_frequencies = {}\n",
    "    for word in text.split():\n",
    "        if word in word_frequencies:\n",
    "            word_frequencies[word] += 1\n",
    "        else:\n",
    "            word_frequencies[word] = 1\n",
    "    # sort the words by frequency in descending order\n",
    "    sorted_words = sorted(word_frequencies.items(), key=lambda x: x[1], reverse=True)\n",
    "    # get the top 10 most frequent words\n",
    "    top_words = dict(sorted_words[:10])\n",
    "    # create a horizontal bar chart of the most frequent words for this occupation\n",
    "    plt.barh(list(top_words.keys()), list(top_words.values()))\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Word')\n",
    "    plt.title(f'Most Frequent Words for {occupation}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input words match with the occupation: Bilglasmontör',\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# load your dataset into a Pandas DataFrame\n",
    "df = pd.read_csv('clean_occup.csv')\n",
    "\n",
    "# create a TfidfVectorizer object to convert the text descriptions into a numerical matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# fit the TfidfVectorizer object to the text descriptions of the occupations\n",
    "tfidf_matrix = tfidf.fit_transform(df['description'])\n",
    "\n",
    "# get the input words from the user\n",
    "word1 = input(\"Enter the first word: \")\n",
    "word2 = input(\"Enter the second word: \")\n",
    "word3 = input(\"Enter the third word: \")\n",
    "\n",
    "# create a list of the input words\n",
    "input_words = [word1, word2, word3]\n",
    "\n",
    "# convert the input words into a numerical matrix using the TfidfVectorizer object\n",
    "input_matrix = tfidf.transform(input_words)\n",
    "\n",
    "# calculate the cosine similarity between the input matrix and the tfidf matrix for all occupations\n",
    "cosine_similarities = cosine_similarity(input_matrix, tfidf_matrix)\n",
    "\n",
    "# get the index of the occupation with the highest similarity score\n",
    "index = cosine_similarities.argmax()\n",
    "\n",
    "# print the occupation with the highest similarity score\n",
    "print(\"The input words match with the occupation:\", df.iloc[index]['occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input words match with the following occupations:\n",
      "- Arborist/Trädvårdare',\n",
      "- Skadetekniker',\n",
      "- Barmästare',\n",
      "- Reparationssnickare',\n",
      "- Tivoliarbetare',\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# load your dataset into a Pandas DataFrame\n",
    "df = pd.read_csv('clean_occup.csv')\n",
    "\n",
    "# create a TfidfVectorizer object to convert the text descriptions into a numerical matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# fit the TfidfVectorizer object to the text descriptions of the occupations\n",
    "tfidf_matrix = tfidf.fit_transform(df['description'])\n",
    "\n",
    "# get the input words from the user\n",
    "word1 = input(\"Enter the first word: \")\n",
    "word2 = input(\"Enter the second word: \")\n",
    "word3 = input(\"Enter the third word: \")\n",
    "\n",
    "# create a list of the input words\n",
    "input_words = [word1, word2, word3]\n",
    "\n",
    "# convert the input words into a numerical matrix using the TfidfVectorizer object\n",
    "input_matrix = tfidf.transform(input_words)\n",
    "\n",
    "# calculate the cosine similarity between the input matrix and the tfidf matrix for all occupations\n",
    "cosine_similarities = cosine_similarity(input_matrix, tfidf_matrix)\n",
    "\n",
    "# get the top 5 occupations with the highest similarity scores\n",
    "top_indexes = cosine_similarities.argsort()[0][-5:][::-1]\n",
    "\n",
    "# print the top 5 occupations with the highest similarity scores\n",
    "print(\"The input words match with the following occupations:\")\n",
    "for index in top_indexes:\n",
    "    print(\"-\", df.iloc[index]['occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Ny extract_common_words\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def extract_common_words(dataset_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(dataset_file)\n",
    "\n",
    "    # Tokenize the descriptions\n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "    df['tokens'] = df['description'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = stopwords.words('swedish')\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "    # Join tokenized words into a single string\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    # Create a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit the vectorizer on the tokenized descriptions\n",
    "    X = vectorizer.fit_transform(df['tokens'])\n",
    "\n",
    "    # Get the feature names (words) from the vectorizer\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Convert feature_names to a list\n",
    "    feature_names = list(feature_names)\n",
    "\n",
    "    # Extract 50 random but common words\n",
    "    common_words = random.sample(feature_names, 50)\n",
    "\n",
    "    return common_words\n",
    "\n",
    "# Usage\n",
    "def fetch_common_words(): \n",
    "    common_words = extract_common_words('dataset2022.csv')\n",
    "    print(common_words)\n",
    "    return common_words\n",
    "\n",
    "#fetch_common_words()\n",
    "\n",
    "\n",
    "## AI word extract COMMON WORDS 2\n",
    "\n",
    "# fungerar verkligen inte bra än"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

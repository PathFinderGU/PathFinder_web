{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/jon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jon/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## NLTK SET UP ##\n",
    "\n",
    "## Natural language processing, pandas setup\n",
    "\n",
    "#Import tokenization, download stopwords & punkt. Download not needed each run but left in for compatibility.\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import download \n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "## Feed variable with NLTK stopwords\n",
    "stop_words = set(stopwords.words(\"swedish\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/09/srb9_l2x3gncdpn0_zx0r2pm0000gn/T/ipykernel_5397/3695825639.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_occupation'] = cleaned_occupations\n",
      "/var/folders/09/srb9_l2x3gncdpn0_zx0r2pm0000gn/T/ipykernel_5397/3695825639.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_description'] = cleaned_descriptions\n",
      "/var/folders/09/srb9_l2x3gncdpn0_zx0r2pm0000gn/T/ipykernel_5397/3695825639.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_description'] = df['cleaned_description'].str.translate(str.maketrans(replace_dict))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 occupation                                        description\n",
      "0            Projektledare,  {'text': 'Tänk dig de mest högteknologiska ele...\n",
      "1    Databasadministratör',  {'text': 'I denna projektanställning på deltid...\n",
      "2     Journalist/Reporter',  {'text': 'Deltidsskribenter med stort nyhets- ...\n",
      "3     Handläggare/Utredare,  {'text': 'Är du social och vet vad god service...\n",
      "4         Transportledare',  {'text': 'Vill du arbeta med framtidens skogst...\n",
      "..                      ...                                                ...\n",
      "882      Trafiksamordnare',  {'text': 'Göteborg är mitt uppe i ett stort st...\n",
      "883         Svetsingenjör',  {'text': 'För kunds räkning söker vi en Svetsa...\n",
      "884           Komminister',  {'text': 'Beskrivning\\nVi söker dig som vill h...\n",
      "885              Inspektör,  {'text': 'Är du redo för en större uppgift?\\nA...\n",
      "886    Förvaltningsekonom',  {'text': 'Du blir en del av ett team med tätt ...\n",
      "\n",
      "[887 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# read the file and select the relevant columns\n",
    "jobtech_dataset = pd.read_csv('dfsvenska.csv')\n",
    "df = jobtech_dataset[['description', 'occupation']]\n",
    "\n",
    "replace_dict = {'!': '', '@': '', '#': '', '$': '', '%': '', '\\n': ''}\n",
    "\n",
    "# clean the occupation column and create a new column for the cleaned occupation\n",
    "cleaned_occupations = []\n",
    "for index, row in df.iterrows():\n",
    "    occupation = row['occupation'][41:]\n",
    "    cleaned_occupation = occupation.split()[0]\n",
    "    cleaned_occupations.append(cleaned_occupation)\n",
    "df['cleaned_occupation'] = cleaned_occupations\n",
    "\n",
    "cleaned_descriptions = []\n",
    "for index, row in df.iterrows():\n",
    "    description = row['description'][10:]\n",
    "    cleaned_descriptions.append(description)\n",
    "df['cleaned_description'] = cleaned_descriptions\n",
    "\n",
    "\n",
    "df['cleaned_description'] = df['cleaned_description'].str.translate(str.maketrans(replace_dict))\n",
    "\n",
    "\n",
    "# loop through each unique occupation and find the corresponding description(s)\n",
    "occupations = df['cleaned_occupation'].unique()\n",
    "occupation_descriptions = []\n",
    "for occupation in occupations:\n",
    "    description = \"\"\n",
    "    for index, row in df.iterrows():\n",
    "        if row['cleaned_occupation'] == occupation:\n",
    "            description += row['description'] + \" \"\n",
    "    occupation_descriptions.append(description.strip())\n",
    "\n",
    "# create a new dataframe with the occupations and descriptions\n",
    "new_df = pd.DataFrame({'occupation': occupations, 'description': occupation_descriptions})\n",
    "\n",
    "new_df.to_csv('clean_ness.csv', index=False)\n",
    "\n",
    "# print the new dataframe\n",
    "print(new_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "# Code from Canvas:\n",
    "#load pandas, tool for data analysis in Python\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "# load nltk to detect stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "replace_dict = {'OM TJÄNSTEN': ' ', 'ARBETSUPPGIFTER': ' ', 'VI SÖKER DIG SOM': ' ', \n",
    "                 'INFORMATION OM FÖRETAGET': ' ', \"'\" : '', 'text_formatted' : '',\n",
    "                 'company_information' : '', 'needs' : '', 'requirements' : '', \n",
    "                 'conditions' : '', 'None' : '', '!': ' ', ':' : '', ',' : ''} \n",
    "\n",
    "\n",
    "\n",
    "# read the file called 2022.json that is in the same directory and call it jobtech_dataset\n",
    "jobtech_dataset = pd.read_csv('jobtech_dataset2022.csv')\n",
    "# #show the variables names (columns) in the dataset\n",
    "print(jobtech_dataset.columns)\n",
    "#show the first 3 rows (job postings) in the dataset\n",
    "print(jobtech_dataset.head(3))\n",
    "\n",
    "#jobtech_dataset.info()\n",
    "\n",
    "# crop dataset to only wanted columns\n",
    "dataframe = jobtech_dataset[['description', 'occupation']] \n",
    "\n",
    "#dataframe.info()\n",
    "\n",
    "df = pd.DataFrame(columns=dataframe.columns)\n",
    "\n",
    "print('detecting swedish ads..')\n",
    "\n",
    "# iterate over the rows of the original dataframe\n",
    "for index, row in dataframe.iterrows():\n",
    "    # detect the language of the description column using the langdetect library\n",
    "    if detect(row['description']) == 'sv':\n",
    "        # if the language is Swedish, append the row to the new dataframe\n",
    "        df = df.append(row, ignore_index=True)\n",
    "\n",
    "# cleaning the column description\n",
    "print('cleaning description column..')\n",
    "df['description'] = df['description'].str.slice(start=10)\n",
    "df['description'] = df['description'].str.replace('\\\\', 'KOWABUNGA')\n",
    "df['description'] = df['description'].str.replace('KOWABUNGAn', ' ')\n",
    "df['description'] = df['description'].str.replace('KOWABUNGAu202f', ' ')\n",
    "df['description'] = df['description'].str.replace('KOWABUNGAt', ' ')\n",
    "df['description'] = df['description'].str.replace('KOWABUNGAxad', ' ')\n",
    "df['description'] = df['description'].str.replace('KOWABUNGAx95', ' ')\n",
    "df['description'] = df['description'].str.replace('KOWABUNGAxa0', ' ')\n",
    "df['description'] = df['description'].str.replace('KOWABUNGA', ' ')\n",
    "df['description'] = df['description'].replace(replace_dict, regex=True)\n",
    "\n",
    "#Remove stop words from description column\n",
    "print('removing stopwords..')\n",
    "stop_words = set(stopwords.words('swedish'))\n",
    "df['description'] = df['description'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))\n",
    "\n",
    "\n",
    "# Clean Occupation column\n",
    "print('cleaning occupation column..')\n",
    "df['occupation'] = df['occupation'].str.slice(start=40)\n",
    "df['occupation'] = df['occupation'].str.split(\"'\", 2).str[1]\n",
    "\n",
    "'''\n",
    "print(df.columns)\n",
    "#show the first 3 rows (job postings) in the dataset\n",
    "print(df.head(3))\n",
    "df.info()'''\n",
    "\n",
    "# loop through each unique occupation and find the corresponding description(s)\n",
    "print('finding unique occupations..')\n",
    "occupations = df['occupation'].unique()\n",
    "occupation_descriptions = []\n",
    "for occupation in occupations:\n",
    "    description = \"\"\n",
    "    for index, row in df.iterrows():\n",
    "        if row['occupation'] == occupation:\n",
    "            description += row['description'] + \" \"\n",
    "    occupation_descriptions.append(description.strip())\n",
    "\n",
    "# create a new dataframe with the occupations and descriptions\n",
    "new_df = pd.DataFrame({'occupation': occupations, 'description': occupation_descriptions})\n",
    "\n",
    "# print the new dataframe\n",
    "print(new_df)\n",
    "\n",
    "# save the new dataframe to a CSV file\n",
    "new_df.to_csv('dataset2022.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_similar_words(words, threshold=3):\n",
    "    new_words = []\n",
    "    for i, w1 in enumerate(words):\n",
    "        skip_word = False\n",
    "        for j, w2 in enumerate(words[i+1:]):\n",
    "            if is_similar(w1, w2, threshold):\n",
    "                skip_word = True\n",
    "                break\n",
    "        if not skip_word:\n",
    "            new_words.append(w1)\n",
    "    return new_words\n",
    "\n",
    "def is_similar(word1, word2, threshold=3):\n",
    "    dist = levenshtein_distance(word1, word2)\n",
    "    return dist <= threshold\n",
    "\n",
    "# Användning:\n",
    "words = read('ord_till_frontend.txt')\n",
    "new_words = remove_similar_words(words, threshold=2)\n",
    "print(new_words) # ['hello', 'world', 'goodbye']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def remove_similar_words(words, threshold=3):\n",
    "    new_words = []\n",
    "    for i, w1 in enumerate(words):\n",
    "        skip_word = False\n",
    "        for j, w2 in enumerate(words[i+1:]):\n",
    "            if is_similar(w1, w2, threshold):\n",
    "                skip_word = True\n",
    "                break\n",
    "        if not skip_word:\n",
    "            new_words.append(w1)\n",
    "    return new_words\n",
    "\n",
    "def is_similar(word1, word2, threshold=3):\n",
    "    dist = levenshtein_distance(word1, word2)\n",
    "    return dist <= threshold\n",
    "\n",
    "def levenshtein_distance(s1, s2):\n",
    "    m = len(s1)\n",
    "    n = len(s2)\n",
    "    dist = np.zeros((m+1, n+1))\n",
    "    for i in range(1, m+1):\n",
    "        dist[i, 0] = i\n",
    "    for j in range(1, n+1):\n",
    "        dist[0, j] = j\n",
    "    for j in range(1, n+1):\n",
    "        for i in range(1, m+1):\n",
    "            if s1[i-1] == s2[j-1]:\n",
    "                dist[i, j] = dist[i-1, j-1]\n",
    "            else:\n",
    "                dist[i, j] = 1 + min(dist[i-1, j], dist[i, j-1], dist[i-1, j-1])\n",
    "    return dist[m, n]\n",
    "\n",
    "# Läs in textfilen och skapa en lista av orden\n",
    "with open('/Users/jon/Documents/GitHub/PathFinder/ord_till_frontend.txt', 'r') as file:\n",
    "    words = file.read().splitlines()\n",
    "\n",
    "# Ta bort liknande ord från listan\n",
    "new_words = remove_similar_words(words, threshold=2)\n",
    "\n",
    "# Skriv de kvarvarande orden till en annan textfil\n",
    "with open('nytextfil.txt', 'w') as file:\n",
    "    for word in new_words:\n",
    "        file.write(word + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "+++ \n",
      "@@ -1,4 +0,0 @@\n",
      "-Organiserad\n",
      "-Självgående\n",
      "-Samarbetande\n",
      "-Analytisk\n",
      "@@ -6,5 +1,0 @@\n",
      "-Uthållig\n",
      "-Kreativ\n",
      "-Kommunikativ\n",
      "-Flexibel\n",
      "-Kundorienterad\n",
      "@@ -17,3 +7,0 @@\n",
      "-Lösningsorienterad\n",
      "-Ansvarsfull\n",
      "-Driven\n",
      "@@ -52 +39,0 @@\n",
      "-Pålitlig\n",
      "@@ -54,2 +40,0 @@\n",
      "-Effektiv\n",
      "-Flexibel\n",
      "@@ -58 +42,0 @@\n",
      "-Kreativ\n",
      "@@ -60,2 +43,0 @@\n",
      "-Kommunikativ\n",
      "-Samarbetande\n",
      "@@ -64,2 +45,0 @@\n",
      "-Analytisk\n",
      "-Flexibel\n",
      "@@ -67,2 +46,0 @@\n",
      "-Resultatorienterad\n",
      "-Innovativ\n",
      "@@ -73 +50,0 @@\n",
      "-Lösningsfokuserad\n",
      "@@ -76 +52,0 @@\n",
      "-Pålitlig\n",
      "@@ -91 +66,0 @@\n",
      "-Resultatorienterad\n",
      "@@ -96 +70,0 @@\n",
      "-Ansvarstagande\n",
      "@@ -101,101 +74,0 @@\n",
      "-Organiserad\n",
      "-Självgående\n",
      "-Samarbetande\n",
      "-Analytisk\n",
      "-Resultatinriktad\n",
      "-Uthållig\n",
      "-Kreativ\n",
      "-Kommunikativ\n",
      "-Flexibel\n",
      "-Kundorienterad\n",
      "-Teamplayer\n",
      "-Kundservice\n",
      "-Försäljning\n",
      "-Marknadsföring\n",
      "-Projektledning\n",
      "-Strategisk\n",
      "-Lösningsorienterad\n",
      "-Ansvarsfull\n",
      "-Driven\n",
      "-Tidsplanering\n",
      "-Affärsutveckling\n",
      "-Budgetansvarig\n",
      "-Ledarskap\n",
      "-Utveckling\n",
      "-Utbildning\n",
      "-Forskning\n",
      "-Hållbarhet\n",
      "-Produktutveckling\n",
      "-Kvalitetssäkring\n",
      "-Teknik\n",
      "-Administration\n",
      "-Ekonomi\n",
      "-Kvalitet\n",
      "-Resor\n",
      "-IT\n",
      "-Design\n",
      "-Hälso- och sjukvård\n",
      "-Juridik\n",
      "-Logistik\n",
      "-Inköp\n",
      "-Projektstyrning\n",
      "-Human resources\n",
      "-Rekrytering\n",
      "-Affärssystem\n",
      "-Affärsmannaskap\n",
      "-Operativt arbete\n",
      "-Skatt\n",
      "-Redovisning\n",
      "-Konflikthantering\n",
      "-Entreprenörskap\n",
      "-Kompetent\n",
      "-Pålitlig\n",
      "-Ansvarsfull\n",
      "-Effektiv\n",
      "-Flexibel\n",
      "-Engagerad\n",
      "-Initiativrik\n",
      "-Kreativ\n",
      "-Organiserad\n",
      "-Kommunikativ\n",
      "-Samarbetande\n",
      "-Problemlösare\n",
      "-Självgående\n",
      "-Analytisk\n",
      "-Flexibel\n",
      "-Ambitiös\n",
      "-Resultatorienterad\n",
      "-Innovativ\n",
      "-Strukturerad\n",
      "-Tidsmedveten\n",
      "-Utåtriktad\n",
      "-Målinriktad\n",
      "-Lösningsfokuserad\n",
      "-Lyhörd\n",
      "-Anpassningsbar\n",
      "-Pålitlig\n",
      "-Uthållig\n",
      "-Uppfinningsrik\n",
      "-Kundorienterad\n",
      "-Teamorienterad\n",
      "-Empatisk\n",
      "-Beslutsam\n",
      "-Självsäker\n",
      "-Proaktiv\n",
      "-Kvalitetsmedveten\n",
      "-Diplomatisk\n",
      "-Initiativtagande\n",
      "-Driven\n",
      "-Flexibel\n",
      "-Analytisk\n",
      "-Resultatorienterad\n",
      "-Innovativ\n",
      "-Kreativ\n",
      "-Kommunikativ\n",
      "-Effektiv\n",
      "-Ansvarstagande\n",
      "-Pålitlig\n",
      "-Samarbetsvillig\n",
      "-Serviceinriktad\n",
      "-Lösningsorienterad\n",
      "-Kundhantering\n",
      "@@ -207 +79,0 @@\n",
      "-Analytisk förmåga\n",
      "@@ -210 +81,0 @@\n",
      "-Innovativt tänkande\n",
      "@@ -233 +103,0 @@\n",
      "-Produkthantering\n",
      "@@ -282 +151,0 @@\n",
      "-Projektutvärdering\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "# Öppna textfilerna och läs in innehållet\n",
    "with open('/Users/jon/Documents/GitHub/PathFinder/ord_till_frontend.txt', 'r') as file1, open('/Users/jon/Documents/GitHub/PathFinder/work in progress/nytextfil.txt', 'r') as file2:\n",
    "    text1 = file1.read()\n",
    "    text2 = file2.read()\n",
    "\n",
    "# Skapa en differens mellan texterna\n",
    "diff = difflib.unified_diff(text1.splitlines(), text2.splitlines(), lineterm='', n=0)\n",
    "\n",
    "# Skriv ut skillnaderna\n",
    "for line in diff:\n",
    "    print(line)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
